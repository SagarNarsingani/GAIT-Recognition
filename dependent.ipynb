{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import imutils\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 88\n",
    "img_width = 128\n",
    "\n",
    "num_classes = 124\n",
    "train_data_dir = './training_data/'\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "val_split = 0.2\n",
    "\n",
    "f1 = 40; k1 = 3; s1 = 2\n",
    "f2 = 32; k2 = 5; s2 = 3\n",
    "drop = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(subject):\n",
    "    sub = str(subject)\n",
    "    if(len(sub)==1): sub = '00' + sub\n",
    "    elif(len(sub)==2): sub = '0' + sub\n",
    "    return sub\n",
    "\n",
    "subjects = 124\n",
    "subject_ids = [get_id(i) for i in range(1, subjects+1)] \n",
    "conditions = ['bg-01', 'bg-02', 'cl-01', 'cl-02', 'nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05', 'nm-06']\n",
    "views = ['000', '018', '036', '054', '072', '090', '108', '126', '144', '162', '180']\n",
    "\n",
    "paths = []\n",
    "for subject in subject_ids:\n",
    "    for condition in conditions:\n",
    "        for view in views:\n",
    "            path = subject + '/' + condition + '/' + view + '/'\n",
    "            paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./training_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in subject_ids:\n",
    "    os.mkdir('./training_data/%s'%sub)\n",
    "    for i in range(1,5):\n",
    "       files = glob.glob('./GEnIs/%s/*nm-0%s*'%(sub, i))\n",
    "       for file in files:\n",
    "        shutil.copy(file, './training_data/%s/'%sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./testing_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in subject_ids:\n",
    "    os.mkdir('./testing_data/%s'%sub)\n",
    "    for i in range(5,7):\n",
    "       files = glob.glob('./GEnIs/%s/*nm-0%s*'%(sub, i))\n",
    "       for file in files:\n",
    "        shutil.copy(file, './testing_data/%s/'%sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 random sequence in training\n",
    "# remaining 4 in testing\n",
    "# for each subject per angle\n",
    "files = glob.glob('./training_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "  \n",
    "files = glob.glob('./testing_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in subject_ids:\n",
    "    os.mkdir('./training_data/%s'%sub)\n",
    "    os.mkdir('./testing_data/%s'%sub)\n",
    "    c = []\n",
    "    for i in range(0, 6):\n",
    "       t = random.choice(conditions)\n",
    "       while t in c:\n",
    "         t = random.choice(conditions)\n",
    "       c.append(t)\n",
    "    \n",
    "    for i in c:\n",
    "       files = glob.glob('./GEnIs/%s/*%s*'%(sub, i))\n",
    "       for file in files:\n",
    "        shutil.copy(file, './training_data/%s/'%sub)\n",
    "    \n",
    "    for i in conditions:\n",
    "       if i not in c:\n",
    "          files = glob.glob('./GEnIs/%s/*%s*'%(sub, i))\n",
    "          for file in files:\n",
    "            shutil.copy(file, './testing_data/%s/'%sub)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./training_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in subject_ids:\n",
    "    os.mkdir('./training_data/%s'%sub)\n",
    "    \n",
    "    for i in ['nm-01', 'nm-02', 'nm-03', 'nm-04']:\n",
    "        files = glob.glob('./GEnIs/%s/*%s*'%(sub, i))\n",
    "        for file in files:\n",
    "         shutil.copy(file, './training_data/%s/'%sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the sequences of angle 90 in training\n",
    "# all other angles in testing\n",
    "\n",
    "# files = glob.glob('./training_data/*')\n",
    "# for f in files:\n",
    "#     shutil.rmtree(f)\n",
    "\n",
    "files = glob.glob('./testing_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in subject_ids:\n",
    "    # os.mkdir('./training_data/%s'%sub)\n",
    "    os.mkdir('./testing_data/%s'%sub)\n",
    "    # files = glob.glob('./GEnIs/%s/*%s*'%(sub, '090'))\n",
    "    # for file in files:\n",
    "    #     shutil.copy(file, './training_data/%s/'%sub)\n",
    "    \n",
    "    for v in ['126']:\n",
    "        files = glob.glob('./GEnIs/%s/*%s*'%(sub, v))\n",
    "        for file in files:\n",
    "            shutil.copy(file, './testing_data/%s/'%sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15876 files belonging to 124 classes.\n",
      "Using 12701 files for training.\n",
      "Found 15876 files belonging to 124 classes.\n",
      "Using 3175 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# building data \n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_data_dir,\n",
    "  seed=114,\n",
    "  subset='training',\n",
    "  batch_size=batch_size,\n",
    "  validation_split=val_split,\n",
    "  image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_data_dir,\n",
    "  seed=114,\n",
    "  subset=\"validation\",\n",
    "  batch_size=batch_size,\n",
    "  validation_split=val_split,\n",
    "  image_size=(img_height, img_width),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_batches = tf.data.experimental.cardinality(val_data)\n",
    "# test_data = val_data.take((2*val_batches) // 3)\n",
    "# val_data = val_data.skip((2*val_batches) // 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache method will help to cache the data during the first epoch\n",
    "# prefetch method basically loads the next batch of data while the current batch is being processed.\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=f1, kernel_size=k1, strides=s1, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "    layers.Conv2D(filters=f2, kernel_size=k2, strides=s2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(1024, use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 88, 128, 3)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 44, 64, 40)        1120      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 44, 64, 40)       160       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 32, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 32, 40)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 11, 32)         32032     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 11, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 5, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 480)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              491520    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 124)               127100    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 656,156\n",
      "Trainable params: 653,964\n",
      "Non-trainable params: 2,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199/199 [==============================] - 40s 192ms/step - loss: 3.9664 - accuracy: 0.1358 - val_loss: 6.6623 - val_accuracy: 0.0110\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 47s 235ms/step - loss: 2.0852 - accuracy: 0.4533 - val_loss: 5.7350 - val_accuracy: 0.0595\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 34s 172ms/step - loss: 1.2928 - accuracy: 0.6453 - val_loss: 1.7734 - val_accuracy: 0.5178\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 33s 164ms/step - loss: 0.9064 - accuracy: 0.7481 - val_loss: 0.6747 - val_accuracy: 0.8255\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 37s 188ms/step - loss: 0.6951 - accuracy: 0.8042 - val_loss: 0.4627 - val_accuracy: 0.8813\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 42s 210ms/step - loss: 0.5487 - accuracy: 0.8425 - val_loss: 0.3691 - val_accuracy: 0.9033\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 43s 216ms/step - loss: 0.4564 - accuracy: 0.8700 - val_loss: 0.3319 - val_accuracy: 0.9134\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 40s 202ms/step - loss: 0.3900 - accuracy: 0.8847 - val_loss: 0.3159 - val_accuracy: 0.9131\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 43s 215ms/step - loss: 0.3271 - accuracy: 0.9034 - val_loss: 0.2791 - val_accuracy: 0.9279\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 35s 176ms/step - loss: 0.3047 - accuracy: 0.9087 - val_loss: 0.2769 - val_accuracy: 0.9222\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 46s 229ms/step - loss: 0.2637 - accuracy: 0.9208 - val_loss: 0.2524 - val_accuracy: 0.9326\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 33s 166ms/step - loss: 0.2289 - accuracy: 0.9298 - val_loss: 0.2508 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 29s 144ms/step - loss: 0.2168 - accuracy: 0.9332 - val_loss: 0.2232 - val_accuracy: 0.9351\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 28s 139ms/step - loss: 0.2070 - accuracy: 0.9358 - val_loss: 0.2309 - val_accuracy: 0.9332\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 33s 166ms/step - loss: 0.1948 - accuracy: 0.9397 - val_loss: 0.2130 - val_accuracy: 0.9414\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 33s 167ms/step - loss: 0.1812 - accuracy: 0.9449 - val_loss: 0.2043 - val_accuracy: 0.9380\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 31s 155ms/step - loss: 0.1606 - accuracy: 0.9501 - val_loss: 0.2003 - val_accuracy: 0.9449\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 32s 162ms/step - loss: 0.1554 - accuracy: 0.9513 - val_loss: 0.2037 - val_accuracy: 0.9424\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 31s 154ms/step - loss: 0.1496 - accuracy: 0.9532 - val_loss: 0.1985 - val_accuracy: 0.9443\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 30s 152ms/step - loss: 0.1525 - accuracy: 0.9515 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 31s 153ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.2108 - val_accuracy: 0.9408\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 35s 175ms/step - loss: 0.1315 - accuracy: 0.9565 - val_loss: 0.2000 - val_accuracy: 0.9461\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 43s 217ms/step - loss: 0.1300 - accuracy: 0.9598 - val_loss: 0.1929 - val_accuracy: 0.9458\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 46s 231ms/step - loss: 0.1234 - accuracy: 0.9623 - val_loss: 0.1892 - val_accuracy: 0.9458\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 36s 183ms/step - loss: 0.1105 - accuracy: 0.9673 - val_loss: 0.1916 - val_accuracy: 0.9446\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 40s 201ms/step - loss: 0.1205 - accuracy: 0.9612 - val_loss: 0.1908 - val_accuracy: 0.9480\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 39s 194ms/step - loss: 0.1189 - accuracy: 0.9610 - val_loss: 0.1920 - val_accuracy: 0.9461\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 38s 189ms/step - loss: 0.1075 - accuracy: 0.9661 - val_loss: 0.1984 - val_accuracy: 0.9465\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 41s 204ms/step - loss: 0.1075 - accuracy: 0.9662 - val_loss: 0.1742 - val_accuracy: 0.9518\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 34s 171ms/step - loss: 0.0925 - accuracy: 0.9717 - val_loss: 0.2027 - val_accuracy: 0.9427\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 41s 205ms/step - loss: 0.0973 - accuracy: 0.9698 - val_loss: 0.1713 - val_accuracy: 0.9512\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 42s 210ms/step - loss: 0.1009 - accuracy: 0.9683 - val_loss: 0.1610 - val_accuracy: 0.9569\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 35s 173ms/step - loss: 0.0960 - accuracy: 0.9700 - val_loss: 0.2208 - val_accuracy: 0.9446\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 35s 174ms/step - loss: 0.0982 - accuracy: 0.9670 - val_loss: 0.1746 - val_accuracy: 0.9553\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 34s 172ms/step - loss: 0.0925 - accuracy: 0.9712 - val_loss: 0.1845 - val_accuracy: 0.9512\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 41s 207ms/step - loss: 0.0894 - accuracy: 0.9706 - val_loss: 0.1811 - val_accuracy: 0.9543\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 40s 200ms/step - loss: 0.0815 - accuracy: 0.9736 - val_loss: 0.1780 - val_accuracy: 0.9543\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 40s 202ms/step - loss: 0.0801 - accuracy: 0.9746 - val_loss: 0.1681 - val_accuracy: 0.9572\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 39s 197ms/step - loss: 0.0756 - accuracy: 0.9752 - val_loss: 0.1597 - val_accuracy: 0.9559\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 38s 193ms/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 0.1689 - val_accuracy: 0.9531\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 35s 175ms/step - loss: 0.0830 - accuracy: 0.9731 - val_loss: 0.1985 - val_accuracy: 0.9461\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 36s 180ms/step - loss: 0.0787 - accuracy: 0.9746 - val_loss: 0.1914 - val_accuracy: 0.9493\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 38s 192ms/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 0.1890 - val_accuracy: 0.9506\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 39s 196ms/step - loss: 0.0753 - accuracy: 0.9764 - val_loss: 0.1640 - val_accuracy: 0.9550\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 41s 208ms/step - loss: 0.0658 - accuracy: 0.9778 - val_loss: 0.1702 - val_accuracy: 0.9540\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 44s 220ms/step - loss: 0.0727 - accuracy: 0.9756 - val_loss: 0.1668 - val_accuracy: 0.9559\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 41s 205ms/step - loss: 0.0658 - accuracy: 0.9797 - val_loss: 0.1744 - val_accuracy: 0.9531\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 35s 176ms/step - loss: 0.0617 - accuracy: 0.9783 - val_loss: 0.1764 - val_accuracy: 0.9499\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 35s 174ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 0.1623 - val_accuracy: 0.9528\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 37s 187ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.1698 - val_accuracy: 0.9499\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 35s 178ms/step - loss: 0.0611 - accuracy: 0.9787 - val_loss: 0.1666 - val_accuracy: 0.9565\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 33s 164ms/step - loss: 0.0636 - accuracy: 0.9788 - val_loss: 0.1438 - val_accuracy: 0.9638\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 32s 163ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.1667 - val_accuracy: 0.9584\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 33s 165ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.1857 - val_accuracy: 0.9518\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 35s 176ms/step - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.1601 - val_accuracy: 0.9622\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 39s 198ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.1736 - val_accuracy: 0.9556\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 40s 200ms/step - loss: 0.0592 - accuracy: 0.9812 - val_loss: 0.1690 - val_accuracy: 0.9575\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 33s 163ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.1709 - val_accuracy: 0.9584\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 39s 195ms/step - loss: 0.0532 - accuracy: 0.9808 - val_loss: 0.1671 - val_accuracy: 0.9569\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 39s 196ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.1798 - val_accuracy: 0.9562\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 39s 196ms/step - loss: 0.0617 - accuracy: 0.9795 - val_loss: 0.1903 - val_accuracy: 0.9509\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 36s 181ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 0.1463 - val_accuracy: 0.9606\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 33s 163ms/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.1513 - val_accuracy: 0.9616\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 32s 162ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.1706 - val_accuracy: 0.9550\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 31s 154ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.1690 - val_accuracy: 0.9591\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 30s 152ms/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.1724 - val_accuracy: 0.9559\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 29s 143ms/step - loss: 0.0500 - accuracy: 0.9834 - val_loss: 0.1710 - val_accuracy: 0.9559\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 30s 149ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.1626 - val_accuracy: 0.9575\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.1765 - val_accuracy: 0.9578\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.1819 - val_accuracy: 0.9556\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0465 - accuracy: 0.9836 - val_loss: 0.1809 - val_accuracy: 0.9556\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 27s 138ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.1712 - val_accuracy: 0.9550\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 27s 135ms/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 0.1554 - val_accuracy: 0.9603\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 0.1537 - val_accuracy: 0.9603\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0542 - accuracy: 0.9834 - val_loss: 0.1822 - val_accuracy: 0.9524\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.1824 - val_accuracy: 0.9537\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 27s 138ms/step - loss: 0.0448 - accuracy: 0.9850 - val_loss: 0.1660 - val_accuracy: 0.9591\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.1577 - val_accuracy: 0.9600\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 27s 138ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.1666 - val_accuracy: 0.9581\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 27s 135ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.1507 - val_accuracy: 0.9628\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 27s 138ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.1583 - val_accuracy: 0.9578\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 36s 180ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.1627 - val_accuracy: 0.9609\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 31s 157ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.1585 - val_accuracy: 0.9603\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 28s 138ms/step - loss: 0.0366 - accuracy: 0.9868 - val_loss: 0.1629 - val_accuracy: 0.9572\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.1541 - val_accuracy: 0.9622\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.1431 - val_accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 28s 139ms/step - loss: 0.0351 - accuracy: 0.9889 - val_loss: 0.1669 - val_accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 32s 162ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.1632 - val_accuracy: 0.9603\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 49s 246ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.1622 - val_accuracy: 0.9606\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 46s 233ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.1892 - val_accuracy: 0.9565\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 31s 153ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.1545 - val_accuracy: 0.9581\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 27s 134ms/step - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.1702 - val_accuracy: 0.9600\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.1643 - val_accuracy: 0.9609\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 27s 134ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.1479 - val_accuracy: 0.9613\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 27s 135ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.1414 - val_accuracy: 0.9654\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.1570 - val_accuracy: 0.9666\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.1557 - val_accuracy: 0.9644\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 27s 137ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.1768 - val_accuracy: 0.9578\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 27s 138ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.1645 - val_accuracy: 0.9644\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 27s 136ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.1528 - val_accuracy: 0.9657\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    './testing_data',\n",
    "    seed=114,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "  )\n",
    "\n",
    "  model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 888 files belonging to 124 classes.\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 4.3796 - accuracy: 0.5315\n",
      "Found 918 files belonging to 124 classes.\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.0821 - accuracy: 0.5076\n",
      "Found 896 files belonging to 124 classes.\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 5.5623 - accuracy: 0.4632\n",
      "Found 792 files belonging to 124 classes.\n",
      "13/13 [==============================] - 1s 36ms/step - loss: 6.7786 - accuracy: 0.3712\n",
      "Found 520 files belonging to 124 classes.\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 8.3788 - accuracy: 0.3712\n",
      "Found 497 files belonging to 124 classes.\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 10.6080 - accuracy: 0.2777\n",
      "Found 525 files belonging to 124 classes.\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 10.2485 - accuracy: 0.3010\n",
      "Found 670 files belonging to 124 classes.\n",
      "11/11 [==============================] - 1s 35ms/step - loss: 8.6691 - accuracy: 0.3313\n",
      "Found 691 files belonging to 124 classes.\n",
      "11/11 [==============================] - 1s 33ms/step - loss: 8.0387 - accuracy: 0.3401\n",
      "Found 687 files belonging to 124 classes.\n",
      "11/11 [==============================] - 1s 34ms/step - loss: 7.1236 - accuracy: 0.4148\n",
      "Found 719 files belonging to 124 classes.\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 4.7069 - accuracy: 0.5118\n"
     ]
    }
   ],
   "source": [
    "for v in views:\n",
    "\n",
    "  # remove current data from training folder\n",
    "  files = glob.glob('./testing_data/*')\n",
    "  for f in files:\n",
    "      shutil.rmtree(f)\n",
    "\n",
    "  for sub in subject_ids:\n",
    "    os.mkdir('./testing_data/%s'%sub)\n",
    "    for i in ['nm-05', 'nm-06']:\n",
    "          files = glob.glob('./GEnIs/%s/%s*%s*'%(sub, i, v))\n",
    "          for file in files:\n",
    "            shutil.copy(file, './testing_data/%s/'%sub)\n",
    "  test()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
