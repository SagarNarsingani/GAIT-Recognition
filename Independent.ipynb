{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = keras.models.load_model('./models/1000')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import imutils\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 88\n",
    "img_width = 128\n",
    "\n",
    "def get_id(subject):\n",
    "    sub = str(subject)\n",
    "    if(len(sub)==1): sub = '00' + sub\n",
    "    elif(len(sub)==2): sub = '0' + sub\n",
    "    return sub\n",
    "\n",
    "subjects = 124\n",
    "subject_ids = [get_id(i) for i in range(1, subjects+1)] \n",
    "conditions = ['bg-01', 'bg-02', 'cl-01', 'cl-02', 'nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05', 'nm-06']\n",
    "views = ['000', '018', '036', '054', '072', '090', '108', '126', '144', '162', '180']\n",
    "\n",
    "paths = []\n",
    "for subject in subject_ids:\n",
    "    for condition in conditions:\n",
    "        for view in views:\n",
    "            path = subject + '/' + condition + '/' + view + '/'\n",
    "            paths.append(path)\n",
    "\n",
    "\n",
    "file = open('./Results/gait_cycles.txt', \"r\")\n",
    "cycles = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- PreProcessing ------------------------------------ #\n",
    "# function to find vertical boundary of the subject in image\n",
    "@njit\n",
    "def find_boundary_y(image):\n",
    "    y1 = -1\n",
    "    y2 = -1\n",
    "    \n",
    "    Y = image.shape[0]\n",
    "    X = image.shape[1]\n",
    "\n",
    "    for y in range(0, Y):\n",
    "        last = -1\n",
    "        for x in range(0, X):\n",
    "            if(image[y, x]!=0):\n",
    "                if(y1==-1):\n",
    "                    y1 = y\n",
    "                last = y\n",
    "        if(last!=-1):\n",
    "            y2 = y\n",
    "\n",
    "    return y1, y2\n",
    "\n",
    "# function to find horizontal boundary of the subject in image\n",
    "@njit\n",
    "def find_boundary_x(image):\n",
    "    x1 = -1\n",
    "    x2 = -1\n",
    "\n",
    "    Y = image.shape[0]\n",
    "    X = image.shape[1]\n",
    "\n",
    "    for x in range(0, X):\n",
    "        last = -1\n",
    "        for y in range(0, Y):\n",
    "            if(image[y, x]!=0):\n",
    "                if(x1==-1):\n",
    "                    x1 = x\n",
    "                last = x\n",
    "        if(last!=-1):\n",
    "            x2 = last\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# function to find horizontal meadian\n",
    "def find_median_x(image):\n",
    "    x1, x2 = find_boundary_x(image)\n",
    "\n",
    "    if ((x1+x2)&1):\n",
    "        return (x1+x2)//2\n",
    "    else :\n",
    "        return (x1+x2)/2\n",
    "\n",
    "# function to preprocess given image and bring the subject in the center.\n",
    "def preprocess_image(image):\n",
    "    y1, y2 = find_boundary_y(image)\n",
    "\n",
    "    if(y1==-1): return [[]]\n",
    "    \n",
    "    image = image[y1:y2+1, :]\n",
    "    image = imutils.resize(image, height=img_height)\n",
    "\n",
    "\n",
    "    meadian = find_median_x(image)\n",
    "    center = image.shape[1] // 2\n",
    "    image = imutils.translate(image, x=(center-meadian), y=0)\n",
    "\n",
    "    image = image[:, center-64 : center+64]\n",
    "    return image\n",
    "\n",
    "# function to get sequence of silhouette for given subject.\n",
    "def preprocess_seq(path):\n",
    "    images = Path('../dataset/' + path).glob('*.png')\n",
    "    for img in images:\n",
    "        silhouette = cv2.imread('../dataset/' + path + img.name, cv2.IMREAD_UNCHANGED)\n",
    "        silhouette = silhouette // 255;\n",
    "        silhouette = preprocess_image(silhouette)\n",
    "        if(len(silhouette[0])==0): continue\n",
    "        cv2.imwrite(os.path.join('./data/' + path, img.name), silhouette*255)\n",
    "    return\n",
    "\n",
    "def preprocess():\n",
    "    for path in paths:\n",
    "        preprocess_seq(path)\n",
    "                \n",
    "# preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_seq(path):\n",
    "    folder = './data/' + path\n",
    "    seq = []\n",
    "    for img in os.listdir(folder):\n",
    "        silhouette = cv2.imread(os.path.join(folder + img), cv2.IMREAD_UNCHANGED)\n",
    "        silhouette = silhouette // 255;\n",
    "        if(silhouette.shape == (img_height, img_width)): seq.append(silhouette)\n",
    "    np_seq = np.array(seq)\n",
    "    return np_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Gait Cycle detection --------------------------- #\n",
    "@njit\n",
    "def detect_gait_cycle(seq=np.array([[[]]]), start=20, end=40):\n",
    "    total_frames = len(seq)\n",
    "    # to do: manage the shift for subjects with less images\n",
    "    \n",
    "    gait_cycle_frames = 0\n",
    "    max_similarity = -1\n",
    "\n",
    "    # correlations = np.array()\n",
    "\n",
    "    for N in range(start, end+1):\n",
    "        if(total_frames <= N): break\n",
    "\n",
    "        # finding auto-correlation of the sequence, for given shift N.\n",
    "        \n",
    "        numerator =0\n",
    "        denominator1 = 0\n",
    "        denominator2 = 0\n",
    "        for n in range(0, total_frames - N):\n",
    "            numerator = numerator + np.sum(np.multiply(seq[n], seq[n+N]))\n",
    "            denominator1 = denominator1 + np.sum(np.multiply(seq[n], seq[n]))\n",
    "            denominator2 = denominator2 + np.sum(np.multiply(seq[n+N], seq[n+N]))\n",
    "\n",
    "        denominator1 = np.sqrt(denominator1)\n",
    "        denominator2 = np.sqrt(denominator2)\n",
    "\n",
    "        # calculating similarity\n",
    "        similarity = numerator / (denominator1 * denominator2)\n",
    "\n",
    "        # correlations.append(similarity)\n",
    "\n",
    "        # will consider the shift which gives maximum similarity.\n",
    "        if(max_similarity < similarity):\n",
    "            gait_cycle_frames = N\n",
    "            max_similarity = similarity\n",
    "\n",
    "    # generate_video(seq, gait_cycle_frames)\n",
    "    # return gait_cycle_frames, correlations\n",
    "    return gait_cycle_frames\n",
    "\n",
    "def compute_get_cycles():\n",
    "    file = open('./gait_cycles.txt', 'w')\n",
    "    for path in paths:\n",
    "        seq = get_silhouette_seq(path)\n",
    "        cycle =  str(detect_gait_cycle(seq)) if len(seq) else '0'\n",
    "        file.write(cycle+'\\n')\n",
    "    file.close()\n",
    "\n",
    "# compute_get_cycles()\n",
    "\n",
    "# def generate_video(seq, gait_cycle):\n",
    "#     out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 1, (img_width, img_height), False)\n",
    "\n",
    "#     for i in range(0,gait_cycle):\n",
    "#         out.write(seq[i] * 255)\n",
    "    \n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     return\n",
    "\n",
    "# cycle, correlations = detect_gait_cycle(1)\n",
    "# shift = [y for y in range(20, 41)]\n",
    "# plt.xlim(15, 45)\n",
    "# plt.plot(shift, correlations)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- Generating GEIs ------------------------------ #\n",
    "\n",
    "# function to get GEI for given sequence of the frames.\n",
    "@njit\n",
    "def get_GEI(seq, cycle):\n",
    "    geis = []\n",
    "    start = 0\n",
    "    n = len(seq)\n",
    "    while start <= (n-cycle):\n",
    "        gei = np.zeros((img_height, img_width))\n",
    "        for k in range(0, cycle):\n",
    "            gei = np.add(gei, seq[start+k])\n",
    "        gei = gei / cycle\n",
    "        start = start + cycle\n",
    "        geis.append(gei)\n",
    "    return geis\n",
    "\n",
    "# driver function to generate GEI for given subject.\n",
    "def generate_GEIs():\n",
    "    for i in range(0, len(paths)):\n",
    "        seq = get_silhouette_seq(paths[i])\n",
    "        cycle = int(cycles[i])\n",
    "        if(cycle==0): continue\n",
    "        geis = get_GEI(seq, cycle)\n",
    "        id = 1\n",
    "        for gei in geis:\n",
    "            name = paths[i].split('/')\n",
    "            cv2.imwrite('./GEIs/%s/%s.png'%(name[0], name[1]+'-'+name[2]+'-'+str(id)), gei * 255)\n",
    "            id+=1\n",
    "\n",
    "generate_GEIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Generate Gait Entropy Image ----------------------- #\n",
    "# will find shannon entropy matrix for given sequence of silhouettes.\n",
    "@njit\n",
    "def shannon_entropy(seq, start, cycle):\n",
    "    seq = seq[start:start+cycle]\n",
    "    entropy = np.zeros((img_height, img_width))\n",
    "    for img in seq:\n",
    "        entropy = np.add(entropy, img)\n",
    "    \n",
    "    entropy = entropy / cycle\n",
    "    max_h = 0\n",
    "    min_h = 1\n",
    "    for i in range(entropy.shape[0]):\n",
    "        for j in range(entropy.shape[1]):\n",
    "            p = entropy[i][j]\n",
    "            if(p==0 or p==1):\n",
    "                entropy[i][j] = 0\n",
    "                continue\n",
    "            entropy[i][j] = -(p*np.log2(p) + (1-p)*np.log2(1-p))\n",
    "            max_h = max(entropy[i][j], max_h)\n",
    "            min_h = min(entropy[i][j], min_h) \n",
    "    \n",
    "    return min_h, max_h, entropy\n",
    "\n",
    "def generate_GEnIs():\n",
    "    for i in range(0, len(paths)):\n",
    "        path = paths[i]\n",
    "        cycle = int(cycles[i])\n",
    "\n",
    "        if(cycle==0): continue\n",
    "\n",
    "        subject = path.split('/')[0]\n",
    "        condition = path.split('/')[1]\n",
    "        view = path.split('/')[2]\n",
    "\n",
    "        seq = get_silhouette_seq(path)\n",
    "        id=0; start=0; n = len(seq)\n",
    "        while start<=(n-cycle):\n",
    "            min_h, max_h, GEnI = shannon_entropy(seq, start, cycle)\n",
    "            GEnI = (GEnI - min_h) / (max_h - min_h)\n",
    "            cv2.imwrite('./GEnIs/%s/%s.png'%(subject, condition+'-'+view+'-'+str(id)), GEnI*255)\n",
    "            id+=1\n",
    "            start+=cycle\n",
    "    return\n",
    "\n",
    "\n",
    "generate_GEnIs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 74\n",
    "data_dir = './GEnIs/'\n",
    "train_data_dir = './training_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataset for 74 subjects\n",
    "classes = []\n",
    "for i in range(num_classes):\n",
    "    label = random.choice(subject_ids)\n",
    "    while label in classes:\n",
    "        label = random.choice(subject_ids)\n",
    "    classes.append(label)\n",
    "\n",
    "\n",
    "files = glob.glob('./training_data/*')\n",
    "for f in files:\n",
    "    shutil.rmtree(f)\n",
    "\n",
    "for sub in classes:\n",
    "    shutil.copytree('./GEnIs/%s'%sub, './training_data/%s'%sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 64\n",
    "val_split = 0.2\n",
    "\n",
    "f1 = 40; k1 = 3; s1 = 2\n",
    "f2 = 32; k2 = 5; s2 = 3\n",
    "drop = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building data \n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_data_dir,\n",
    "  seed=114,\n",
    "  subset='training',\n",
    "  batch_size=batch_size,\n",
    "  validation_split=val_split,\n",
    "  image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_data_dir,\n",
    "  seed=114,\n",
    "  # shuffle=False,\n",
    "  subset=\"validation\",\n",
    "  batch_size=batch_size,\n",
    "  validation_split=val_split,\n",
    "  image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# cache method will help to cache the data during the first epoch\n",
    "# prefetch method basically loads the next batch of data while the current batch is being processed.\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=f1, kernel_size=k1, strides=s1, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "    layers.Conv2D(filters=f2, kernel_size=k2, strides=s2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(1024, use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(drop),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.listdir('./training_data/')\n",
    "img = cv2.imread('./training_data/031/cl-01-090.png')\n",
    "t = np.argmax(model.predict(np.array([img])))\n",
    "temp[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty(path):\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "\n",
    "def KNN(k):\n",
    "    gallery, y_train = get_data('./gallery/*')\n",
    "    probe, y_test = get_data('./probe/*')\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(gallery, y_train)\n",
    "    score = knn.score(probe, y_test) * 100\n",
    "    print(\"for k=%s, \"%k, end=\" \")\n",
    "    print(score)\n",
    "    return knn\n",
    "    \n",
    "\n",
    "def get_layer_data(path, layerIndex=9):\n",
    "    func = keras.backend.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)\n",
    "    img = cv2.imread(path)\n",
    "    layerOutput = func(np.array([img]))  # input_data is a numpy array\n",
    "    return layerOutput[0]\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img in glob.glob(path):\n",
    "        data.append(get_layer_data(img))\n",
    "        labels.append(img.split('\\\\')[1].split('-')[0])\n",
    "    return np.array(data), labels\n",
    "\n",
    "n = 1\n",
    "temp = os.listdir('./training_data/')\n",
    "classes = []\n",
    "for i in subject_ids:\n",
    "    if i not in temp:\n",
    "        classes.append(i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix angle, take 4 normal in gallery for 50 subjects...\n",
    "def make_gallery(view):\n",
    "    empty('./gallery/')\n",
    "    for sub in classes:\n",
    "        for env in ['nm-01', 'nm-02', 'nm-03', 'nm-04']:\n",
    "            files = glob.glob('./GEnIs/%s/%s-%s.png'%(sub, env, view))\n",
    "            for file in files:\n",
    "                temp = file.split('/')\n",
    "                name = temp[2] + '-' + temp[3]\n",
    "                shutil.copy(file, './gallery/%s'%name)\n",
    "\n",
    "# take 2 sequences in probe...\n",
    "def make_probe(view):\n",
    "    empty('./probe/')\n",
    "    for sub in classes:\n",
    "        for env in ['cl-01', 'cl-02']:\n",
    "            files = glob.glob('./GEnIs/%s/%s-%s.png'%(sub, env, view))\n",
    "            for file in files:\n",
    "                temp = file.split('/')\n",
    "                name = temp[2] + '-' + temp[3]\n",
    "                shutil.copy(file, './probe/%s'%name)\n",
    "\n",
    "# running for each pair\n",
    "vs = views\n",
    "for i in vs:\n",
    "    for j in vs:\n",
    "        make_gallery(i)\n",
    "        make_probe(j)\n",
    "        print(i, j)\n",
    "        KNN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Experiment - take 50 x 4 x 10 sequences / images in gallery...\n",
    "empty('./gallery/')\n",
    "for v in ['036', '054', '072', '090']:\n",
    "    for sub in classes:\n",
    "        files = glob.glob('./GEnIs/%s/*%s*'%(sub, v))\n",
    "        for file in files:\n",
    "            temp = file.split('/')\n",
    "            name = temp[2].replace('\\\\', '-')\n",
    "            shutil.copy(file, './gallery/%s'%name)\n",
    "\n",
    "train_data = glob.glob('./gallery/*')\n",
    "test_data = random.sample(train_data, (40 * len(train_data))//100)\n",
    "\n",
    "empty('./probe/')\n",
    "for file in test_data:\n",
    "    shutil.move(file, './probe/')\n",
    "\n",
    "KNN(1)\n",
    "\n",
    "# Average accuracy of 10 iterations of this block = 78.81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = np.array([])\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        gallery_view = views[i]\n",
    "        probe_view = views[j]\n",
    "        \n",
    "        print(\"probe=%s\"%probe_view)\n",
    "        print(\"gallery=%s\"%gallery_view)\n",
    "        for cl in [\"nm\", \"bg\", \"cl\"]:\n",
    "            empty('./gallery/')\n",
    "            empty('./probe/')\n",
    "            y_train = []; y_test = []\n",
    "            for cls in classes:\n",
    "                    for g in glob.glob('./GEnIs/%s/%s*%s*.png'%(cls, cl, gallery_view)):\n",
    "                        y_train.append(cls)\n",
    "                        print(g)\n",
    "                        shutil.copy(g, './gallery/%s'%(g.split('/')[2].replace('\\\\', '-')))\n",
    "                    for p in glob.glob('./GEnIs/%s/%s*%s*.png'%(cls, cl, probe_view)):\n",
    "                        y_test.append(cls)\n",
    "                        shutil.copy(p, './probe/%s.png'%(p.split('/')[2].replace('\\\\', '-')))\n",
    "            K = [1, 3, 5, 7, 9]\n",
    "            # 11, 13, 15, 17, 19, 21, 23, 25\n",
    "            curr = np.array([])\n",
    "            print(\"for\", cl)\n",
    "            for k in K:\n",
    "                np.append(curr, KNN(k, y_train, y_test))\n",
    "            np.append(knn, curr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same angle in gallery and probe\n",
    "# 4 normal in gallery, 2 variable in probe\n",
    "knn = np.array([])\n",
    "for i in range(0, n):\n",
    "    view = views[i]\n",
    "    print(\"view angle:\", view)\n",
    "    empty('./gallery/')\n",
    "    empty('./probe/')\n",
    "    y_train = []; y_test = []\n",
    "    for cls in classes:\n",
    "        for c1 in ['01', '02', '03', '04']:\n",
    "            for g in glob.glob('./GEnIs/%s/nm-%s*%s*.png'%(cls, c1, view)):\n",
    "                y_train.append(cls)\n",
    "                shutil.copy(g, './gallery/%s'%(g.split('/')[2].replace('\\\\', '-')))\n",
    "        \n",
    "        for c2 in ['bg-01', 'bg-02']:\n",
    "            for p in glob.glob('./GEnIs/%s/%s*%s*.png'%(cls, c2, view)):\n",
    "                y_test.append(cls)\n",
    "                shutil.copy(p, './probe/%s.png'%(p.split('/')[2].replace('\\\\', '-')))\n",
    "    K = [1, 3, 5, 7, 9]\n",
    "    # 11, 13, 15, 17, 19, 21, 23, 25\n",
    "    curr = np.array([])\n",
    "    for k in K:\n",
    "        np.append(curr, KNN(k, y_train, y_test))\n",
    "    np.append(knn, curr);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e1984914bfec2b620dc72bb669e7a06684a6f70d313211b880fdcdc7f0f0298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
